{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ca75e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# Import the main Libraries\\nimport pandas as pd\\nimport warnings\\nimport joblib\\nwarnings.filterwarnings(\\\"ignore\\\")\\n%reload_ext nb_black\\n\\n\\n##  preprocessing\\nfrom sklearn.model_selection import train_test_split , cross_val_score, StratifiedKFold,cross_val_predict\\nfrom sklearn.pipeline import Pipeline, FeatureUnion\\nfrom sklearn.impute import KNNImputer ,SimpleImputer\\nfrom sklearn.preprocessing import PowerTransformer, OneHotEncoder, OrdinalEncoder, MinMaxScaler\\nfrom sklearn_features.transformers import DataFrameSelector\\nfrom imblearn.over_sampling import SMOTE\\nimport joblib\\n\\n## Models\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom xgboost import XGBClassifier\\n\\n## Evaluation Metric\\nfrom sklearn.metrics import f1_score , make_scorer, accuracy_score\";\n",
       "                var nbb_formatted_code = \"# Import the main Libraries\\nimport pandas as pd\\nimport warnings\\nimport joblib\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n%reload_ext nb_black\\n\\n\\n##  preprocessing\\nfrom sklearn.model_selection import (\\n    train_test_split,\\n    cross_val_score,\\n    StratifiedKFold,\\n    cross_val_predict,\\n)\\nfrom sklearn.pipeline import Pipeline, FeatureUnion\\nfrom sklearn.impute import KNNImputer, SimpleImputer\\nfrom sklearn.preprocessing import (\\n    PowerTransformer,\\n    OneHotEncoder,\\n    OrdinalEncoder,\\n    MinMaxScaler,\\n)\\nfrom sklearn_features.transformers import DataFrameSelector\\nfrom imblearn.over_sampling import SMOTE\\nimport joblib\\n\\n## Models\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom xgboost import XGBClassifier\\n\\n## Evaluation Metric\\nfrom sklearn.metrics import f1_score, make_scorer, accuracy_score\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the main Libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import joblib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%reload_ext nb_black\n",
    "\n",
    "\n",
    "##  preprocessing\n",
    "from sklearn.model_selection import train_test_split , cross_val_score, StratifiedKFold,cross_val_predict\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import KNNImputer ,SimpleImputer\n",
    "from sklearn.preprocessing import PowerTransformer, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn_features.transformers import DataFrameSelector\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "## Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## Evaluation Metric\n",
    "from sklearn.metrics import f1_score , make_scorer, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ee82b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Data path\\npath_df_nature = r\\\"..\\\\data\\\\processed/Nature data.pkl\\\"\";\n",
       "                var nbb_formatted_code = \"# Data path\\npath_df_nature = r\\\"..\\\\data\\\\processed/Nature data.pkl\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data path\n",
    "path_df_nature = r\"..\\data\\processed/Nature data.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421ff7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>favc</th>\n",
       "      <th>fcvc</th>\n",
       "      <th>ncp</th>\n",
       "      <th>caec</th>\n",
       "      <th>smoke</th>\n",
       "      <th>ch2o</th>\n",
       "      <th>scc</th>\n",
       "      <th>faf</th>\n",
       "      <th>tue</th>\n",
       "      <th>calc</th>\n",
       "      <th>mtrans</th>\n",
       "      <th>nobeyesdad</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>53.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  height  weight family_history_with_overweight favc  fcvc   \n",
       "0  Female  21.0    1.62    64.0                            yes   no   2.0  \\\n",
       "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
       "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
       "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
       "5    Male  29.0    1.62    53.0                             no  yes   2.0   \n",
       "\n",
       "   ncp       caec smoke  ch2o  scc  faf  tue        calc   \n",
       "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no  \\\n",
       "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
       "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
       "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
       "5  3.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "\n",
       "                  mtrans          nobeyesdad   bmi  \n",
       "0  Public_Transportation       Normal_Weight  24.4  \n",
       "1  Public_Transportation       Normal_Weight  24.2  \n",
       "2  Public_Transportation       Normal_Weight  23.8  \n",
       "3                Walking  Overweight_Level_I  26.9  \n",
       "5             Automobile       Normal_Weight  20.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"## Load data and print first 5 sample\\ndf_nature = pd.read_pickle(path_df_nature)\\ndf_nature.head()\";\n",
       "                var nbb_formatted_code = \"## Load data and print first 5 sample\\ndf_nature = pd.read_pickle(path_df_nature)\\ndf_nature.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Load data and print first 5 sample\n",
    "df_nature = pd.read_pickle(path_df_nature)\n",
    "df_nature.head()\n",
    "data=[2.0,3.0,2.0,0.0,1.0,24.4,'Sometimes','no','Normal_Weight','yes','no','no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9100e97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape (1041, 12)\n",
      "y_train_shape (1041,)\n",
      "**************************************************\n",
      "x_test_shape (347, 12)\n",
      "y_test_shape (347,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Split dataset into X & Y\\n# Drop specified columns ('nobeyesdad', 'gender', 'age', 'height', 'weight', 'smoke') to create the feature matrix (X)\\n# 'x' will contain the features, and 'y' will contain the target variable\\nx = df_nature.drop(columns=['nobeyesdad', 'gender', 'age', 'height', 'weight', 'smoke'])\\n\\n# 'y' will be the target variable, which is 'nobeyesdad' in this case\\ny = df_nature['nobeyesdad']\\n\\n# Split dataset into training and testing sets\\n# 'x_train' and 'y_train' will contain the training data and labels\\n# 'x_test' and 'y_test' will contain the testing data and labels\\n# The data will be split into a 75% training set and a 25% testing set, with shuffling and a random seed for reproducibility\\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, shuffle=True, random_state=42, stratify=y)\\n\\n# Check the shape of the training and testing datasets\\nprint(\\\"x_train_shape\\\", x_train.shape)\\nprint(\\\"y_train_shape\\\", y_train.shape)\\nprint(\\\"*\\\" * 50)\\nprint(\\\"x_test_shape\\\", x_test.shape)\\nprint(\\\"y_test_shape\\\", y_test.shape)\";\n",
       "                var nbb_formatted_code = \"# Split dataset into X & Y\\n# Drop specified columns ('nobeyesdad', 'gender', 'age', 'height', 'weight', 'smoke') to create the feature matrix (X)\\n# 'x' will contain the features, and 'y' will contain the target variable\\nx = df_nature.drop(columns=[\\\"nobeyesdad\\\", \\\"gender\\\", \\\"age\\\", \\\"height\\\", \\\"weight\\\", \\\"smoke\\\"])\\n\\n# 'y' will be the target variable, which is 'nobeyesdad' in this case\\ny = df_nature[\\\"nobeyesdad\\\"]\\n\\n# Split dataset into training and testing sets\\n# 'x_train' and 'y_train' will contain the training data and labels\\n# 'x_test' and 'y_test' will contain the testing data and labels\\n# The data will be split into a 75% training set and a 25% testing set, with shuffling and a random seed for reproducibility\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.25, shuffle=True, random_state=42, stratify=y\\n)\\n\\n# Check the shape of the training and testing datasets\\nprint(\\\"x_train_shape\\\", x_train.shape)\\nprint(\\\"y_train_shape\\\", y_train.shape)\\nprint(\\\"*\\\" * 50)\\nprint(\\\"x_test_shape\\\", x_test.shape)\\nprint(\\\"y_test_shape\\\", y_test.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split dataset into X & Y\n",
    "# Drop specified columns ('nobeyesdad', 'gender', 'age', 'height', 'weight', 'smoke') to create the feature matrix (X)\n",
    "# 'x' will contain the features, and 'y' will contain the target variable\n",
    "x = df_nature.drop(columns=['nobeyesdad', 'gender', 'age', 'height', 'weight', 'smoke'])\n",
    "\n",
    "# 'y' will be the target variable, which is 'nobeyesdad' in this case\n",
    "y = df_nature['nobeyesdad']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "# 'x_train' and 'y_train' will contain the training data and labels\n",
    "# 'x_test' and 'y_test' will contain the testing data and labels\n",
    "# The data will be split into a 75% training set and a 25% testing set, with shuffling and a random seed for reproducibility\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, shuffle=True, random_state=42, stratify=y)\n",
    "\n",
    "# Check the shape of the training and testing datasets\n",
    "print(\"x_train_shape\", x_train.shape)\n",
    "print(\"y_train_shape\", y_train.shape)\n",
    "print(\"*\" * 50)\n",
    "print(\"x_test_shape\", x_test.shape)\n",
    "print(\"y_test_shape\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb1ae10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Numircal column: ['fcvc', 'ncp', 'ch2o', 'faf', 'tue', 'bmi']\n",
      "Name of Ordinal Categorical column: ['caec', 'calc', 'mtrans']\n",
      "Name of Nominal Categorical column: ['family_history_with_overweight', 'favc', 'scc']\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Get the names of numerical columns (exclude \\\"object\\\" dtype columns)\\nnumircal_col = x_train.select_dtypes(exclude=\\\"object\\\").columns.tolist()\\n\\n# Get the names of ordinal categorical columns\\ncatego_col_ordinal = x_train[[\\\"caec\\\", \\\"calc\\\", \\\"mtrans\\\"]].columns.tolist()\\n\\n# Get the names of nominal categorical columns\\ncatego_col_nominal = x_train[[\\\"family_history_with_overweight\\\", \\\"favc\\\", \\\"scc\\\"]].columns.tolist()\\n\\n# Print the names of the identified columns\\nprint(\\\"Name of Numircal column:\\\", numircal_col)\\nprint(\\\"Name of Ordinal Categorical column:\\\", catego_col_ordinal)\\nprint(\\\"Name of Nominal Categorical column:\\\", catego_col_nominal)\";\n",
       "                var nbb_formatted_code = \"# Get the names of numerical columns (exclude \\\"object\\\" dtype columns)\\nnumircal_col = x_train.select_dtypes(exclude=\\\"object\\\").columns.tolist()\\n\\n# Get the names of ordinal categorical columns\\ncatego_col_ordinal = x_train[[\\\"caec\\\", \\\"calc\\\", \\\"mtrans\\\"]].columns.tolist()\\n\\n# Get the names of nominal categorical columns\\ncatego_col_nominal = x_train[\\n    [\\\"family_history_with_overweight\\\", \\\"favc\\\", \\\"scc\\\"]\\n].columns.tolist()\\n\\n# Print the names of the identified columns\\nprint(\\\"Name of Numircal column:\\\", numircal_col)\\nprint(\\\"Name of Ordinal Categorical column:\\\", catego_col_ordinal)\\nprint(\\\"Name of Nominal Categorical column:\\\", catego_col_nominal)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the names of numerical columns (exclude \"object\" dtype columns)\n",
    "numircal_col = x_train.select_dtypes(exclude=\"object\").columns.tolist()\n",
    "\n",
    "# Get the names of ordinal categorical columns\n",
    "catego_col_ordinal = x_train[[\"caec\", \"calc\", \"mtrans\"]].columns.tolist()\n",
    "\n",
    "# Get the names of nominal categorical columns\n",
    "catego_col_nominal = x_train[[\"family_history_with_overweight\", \"favc\", \"scc\"]].columns.tolist()\n",
    "\n",
    "# Print the names of the identified columns\n",
    "print(\"Name of Numircal column:\", numircal_col)\n",
    "print(\"Name of Ordinal Categorical column:\", catego_col_ordinal)\n",
    "print(\"Name of Nominal Categorical column:\", catego_col_nominal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b9529b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"## Create PipeLine\\n\\n#### Numrical Pipeline\\nnum_pipe = Pipeline(\\n    steps=[\\n        (\\\"selector\\\", DataFrameSelector(numircal_col)),\\n        (\\\"imputer\\\", KNNImputer()),\\n        (\\\"box-cox\\\", PowerTransformer(method=\\\"yeo-johnson\\\", standardize=False)),\\n        (\\\"normalization\\\", MinMaxScaler(feature_range=(-1, 1))),\\n    ]\\n)\\n\\n## Categorical(ordinal) Pipline\\nordinal_pipe = Pipeline(\\n    steps=[\\n        (\\\"selector\\\", DataFrameSelector(catego_col_ordinal)),\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"most_frequent\\\")),\\n        (\\\"encoding\\\", OrdinalEncoder()),\\n    ]\\n)\\n\\n## Categorical(nominal) Pipline\\nnominal_pipe = Pipeline(\\n    steps=[\\n        (\\\"selector\\\", DataFrameSelector(catego_col_nominal)),\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"most_frequent\\\")),\\n        (\\\"encoding\\\", OneHotEncoder(drop=\\\"first\\\", sparse_output=False)),\\n    ]\\n)\\n\\n## Combine all\\nall_pipe = FeatureUnion(\\n    transformer_list=[\\n        (\\\"Numrical\\\", num_pipe),\\n        (\\\"ordinal\\\", ordinal_pipe),\\n        (\\\"nominal\\\", nominal_pipe),\\n    ]\\n)\\n\\n## Apply\\nx_train_finall = all_pipe.fit_transform(x_train)\\nx_test_final = all_pipe.transform(x_test)\";\n",
       "                var nbb_formatted_code = \"## Create PipeLine\\n\\n#### Numrical Pipeline\\nnum_pipe = Pipeline(\\n    steps=[\\n        (\\\"selector\\\", DataFrameSelector(numircal_col)),\\n        (\\\"imputer\\\", KNNImputer()),\\n        (\\\"box-cox\\\", PowerTransformer(method=\\\"yeo-johnson\\\", standardize=False)),\\n        (\\\"normalization\\\", MinMaxScaler(feature_range=(-1, 1))),\\n    ]\\n)\\n\\n## Categorical(ordinal) Pipline\\nordinal_pipe = Pipeline(\\n    steps=[\\n        (\\\"selector\\\", DataFrameSelector(catego_col_ordinal)),\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"most_frequent\\\")),\\n        (\\\"encoding\\\", OrdinalEncoder()),\\n    ]\\n)\\n\\n## Categorical(nominal) Pipline\\nnominal_pipe = Pipeline(\\n    steps=[\\n        (\\\"selector\\\", DataFrameSelector(catego_col_nominal)),\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"most_frequent\\\")),\\n        (\\\"encoding\\\", OneHotEncoder(drop=\\\"first\\\", sparse_output=False)),\\n    ]\\n)\\n\\n## Combine all\\nall_pipe = FeatureUnion(\\n    transformer_list=[\\n        (\\\"Numrical\\\", num_pipe),\\n        (\\\"ordinal\\\", ordinal_pipe),\\n        (\\\"nominal\\\", nominal_pipe),\\n    ]\\n)\\n\\n## Apply\\nx_train_finall = all_pipe.fit_transform(x_train)\\nx_test_final = all_pipe.transform(x_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create PipeLine\n",
    "\n",
    "#### Numrical Pipeline\n",
    "num_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"selector\", DataFrameSelector(numircal_col)),\n",
    "        (\"imputer\", KNNImputer()),\n",
    "        (\"box-cox\", PowerTransformer(method=\"yeo-johnson\", standardize=False)),\n",
    "        (\"normalization\", MinMaxScaler(feature_range=(-1, 1))),\n",
    "    ]\n",
    ")\n",
    "\n",
    "## Categorical(ordinal) Pipline\n",
    "ordinal_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"selector\", DataFrameSelector(catego_col_ordinal)),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoding\", OrdinalEncoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "## Categorical(nominal) Pipline\n",
    "nominal_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"selector\", DataFrameSelector(catego_col_nominal)),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoding\", OneHotEncoder(drop=\"first\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "## Combine all\n",
    "all_pipe = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        (\"Numrical\", num_pipe),\n",
    "        (\"ordinal\", ordinal_pipe),\n",
    "        (\"nominal\", nominal_pipe),\n",
    "    ]\n",
    ")\n",
    "\n",
    "## Apply\n",
    "x_train_finall = all_pipe.fit_transform(x_train)\n",
    "x_test_final = all_pipe.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cb2b84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>favc</th>\n",
       "      <th>fcvc</th>\n",
       "      <th>ncp</th>\n",
       "      <th>caec</th>\n",
       "      <th>ch2o</th>\n",
       "      <th>scc</th>\n",
       "      <th>faf</th>\n",
       "      <th>tue</th>\n",
       "      <th>calc</th>\n",
       "      <th>mtrans</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>2.01</td>\n",
       "      <td>no</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>36.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     family_history_with_overweight favc  fcvc  ncp       caec  ch2o scc   \n",
       "1713                            yes  yes  1.92  3.0  Sometimes  2.01  no  \\\n",
       "\n",
       "       faf   tue       calc      mtrans   bmi  \n",
       "1713  0.18  0.51  Sometimes  Automobile  36.3  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"x_train.iloc[0:1, :]\";\n",
       "                var nbb_formatted_code = \"x_train.iloc[0:1, :]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train.iloc[0:1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0310a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33276166, -0.26793478, -0.05368913, -0.79041125, -0.2400954 ,\n",
       "         0.27550601,  2.        ,  1.        ,  0.        ,  1.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"all_pipe.transform(x_train.iloc[0:1, :])\";\n",
       "                var nbb_formatted_code = \"all_pipe.transform(x_train.iloc[0:1, :])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_pipe.transform(x_train.iloc[0:1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c14339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Target transformation: Map target categories to numerical values\\n# Define a mapping dictionary to map category names to numerical values\\nmap_target={'Insufficient_Weight':0\\n           ,'Normal_Weight':1\\n           ,'Overweight_Level_I':2\\n           ,'Overweight_Level_II':3\\n           ,'Obesity_Type_I':4\\n           ,'Obesity_Type_II':5\\n           ,'Obesity_Type_III':6}\\n\\n# Apply the mapping to the target variable (y_train) in the training set\\ny_train = y_train.map(map_target)\\n\\n# Apply the mapping to the target variable (y_test) in the test set\\ny_test= y_test.map(map_target)\";\n",
       "                var nbb_formatted_code = \"# Target transformation: Map target categories to numerical values\\n# Define a mapping dictionary to map category names to numerical values\\nmap_target = {\\n    \\\"Insufficient_Weight\\\": 0,\\n    \\\"Normal_Weight\\\": 1,\\n    \\\"Overweight_Level_I\\\": 2,\\n    \\\"Overweight_Level_II\\\": 3,\\n    \\\"Obesity_Type_I\\\": 4,\\n    \\\"Obesity_Type_II\\\": 5,\\n    \\\"Obesity_Type_III\\\": 6,\\n}\\n\\n# Apply the mapping to the target variable (y_train) in the training set\\ny_train = y_train.map(map_target)\\n\\n# Apply the mapping to the target variable (y_test) in the test set\\ny_test = y_test.map(map_target)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target transformation: Map target categories to numerical values\n",
    "# Define a mapping dictionary to map category names to numerical values\n",
    "map_target={'Insufficient_Weight':0\n",
    "           ,'Normal_Weight':1\n",
    "           ,'Overweight_Level_I':2\n",
    "           ,'Overweight_Level_II':3\n",
    "           ,'Obesity_Type_I':4\n",
    "           ,'Obesity_Type_II':5\n",
    "           ,'Obesity_Type_III':6}\n",
    "\n",
    "# Apply the mapping to the target variable (y_train) in the training set\n",
    "y_train = y_train.map(map_target)\n",
    "\n",
    "# Apply the mapping to the target variable (y_test) in the test set\n",
    "y_test= y_test.map(map_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9fc25e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before nobeyesdad\n",
      "5    242\n",
      "6    242\n",
      "3    242\n",
      "0    242\n",
      "4    242\n",
      "2    242\n",
      "1    242\n",
      "Name: count, dtype: int64\n",
      "******************************\n",
      "After nobeyesdad\n",
      "6    242\n",
      "5    162\n",
      "1    147\n",
      "4    146\n",
      "3    128\n",
      "2    111\n",
      "0    105\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"## USING SMOTE\\nover = SMOTE()\\nx_train_resample, y_train_resample = over.fit_resample(x_train_finall, y_train)\\n\\n##### check shape\\nprint(\\\"Before\\\", y_train_resample.value_counts())\\nprint(\\\"*\\\" * 30)\\nprint(\\\"After\\\", y_train.value_counts())\";\n",
       "                var nbb_formatted_code = \"## USING SMOTE\\nover = SMOTE()\\nx_train_resample, y_train_resample = over.fit_resample(x_train_finall, y_train)\\n\\n##### check shape\\nprint(\\\"Before\\\", y_train_resample.value_counts())\\nprint(\\\"*\\\" * 30)\\nprint(\\\"After\\\", y_train.value_counts())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## USING SMOTE\n",
    "over = SMOTE()\n",
    "x_train_resample, y_train_resample = over.fit_resample(x_train_finall, y_train)\n",
    "\n",
    "##### check shape\n",
    "print(\"Before\", y_train_resample.value_counts())\n",
    "print(\"*\" * 30)\n",
    "print(\"After\", y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce7451",
   "metadata": {},
   "source": [
    "# `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aa1229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Training Dataset using Logisitic with class_weights 98.175\n",
      "F1 Score for Testing Dataset using Logisitic after class_weights 96.254\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"##w SOMTE\\nlog_clf = LogisticRegression(\\n    penalty=\\\"l2\\\",\\n    tol=0.01,\\n    C=1000,\\n    fit_intercept=True,\\n    random_state=42,\\n    max_iter=1000,\\n)\\n\\nlog_clf.fit(x_train_resample, y_train_resample)  ### Learn\\n\\n## Predict and Evaluation model\\ny_pred_log_train = log_clf.predict(x_train_finall)\\ny_pred_log_test = log_clf.predict(x_test_final)\\n\\n## Evaluation model\\nf1_train_log = f1_score(y_train, y_pred_log_train, average=\\\"micro\\\")\\nf1_test_log = f1_score(y_test, y_pred_log_test, average=\\\"micro\\\")\\n\\nprint(\\n    f\\\"F1 Score for Training Dataset using Logisitic with class_weights {f1_train_log * 100 :.3f}\\\"\\n)\\nprint(\\n    f\\\"F1 Score for Testing Dataset using Logisitic after class_weights {f1_test_log * 100 :.3f}\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"##w SOMTE\\nlog_clf = LogisticRegression(\\n    penalty=\\\"l2\\\",\\n    tol=0.01,\\n    C=1000,\\n    fit_intercept=True,\\n    random_state=42,\\n    max_iter=1000,\\n)\\n\\nlog_clf.fit(x_train_resample, y_train_resample)  ### Learn\\n\\n## Predict and Evaluation model\\ny_pred_log_train = log_clf.predict(x_train_finall)\\ny_pred_log_test = log_clf.predict(x_test_final)\\n\\n## Evaluation model\\nf1_train_log = f1_score(y_train, y_pred_log_train, average=\\\"micro\\\")\\nf1_test_log = f1_score(y_test, y_pred_log_test, average=\\\"micro\\\")\\n\\nprint(\\n    f\\\"F1 Score for Training Dataset using Logisitic with class_weights {f1_train_log * 100 :.3f}\\\"\\n)\\nprint(\\n    f\\\"F1 Score for Testing Dataset using Logisitic after class_weights {f1_test_log * 100 :.3f}\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##w SOMTE\n",
    "log_clf = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    tol=0.01,\n",
    "    C=1000,\n",
    "    fit_intercept=True,\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "log_clf.fit(x_train_resample, y_train_resample)  ### Learn\n",
    "\n",
    "## Predict and Evaluation model\n",
    "y_pred_log_train = log_clf.predict(x_train_finall)\n",
    "y_pred_log_test = log_clf.predict(x_test_final)\n",
    "\n",
    "## Evaluation model\n",
    "f1_train_log = f1_score(y_train, y_pred_log_train, average=\"micro\")\n",
    "f1_test_log = f1_score(y_test, y_pred_log_test, average=\"micro\")\n",
    "\n",
    "print(\n",
    "    f\"F1 Score for Training Dataset using Logisitic with class_weights {f1_train_log * 100 :.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"F1 Score for Testing Dataset using Logisitic after class_weights {f1_test_log * 100 :.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462ee60e",
   "metadata": {},
   "source": [
    "# `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defda0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Training Dataset using RandomForest  94.813\n",
      "F1Score for Testing Dataset using RandomForest  95.965\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"### Bagging------> RandomForestClassifier\\nrf_clf = RandomForestClassifier(\\n    n_estimators=100,\\n    criterion=\\\"gini\\\",\\n    max_depth=10,\\n    max_leaf_nodes=4,\\n    oob_score=True,\\n    min_impurity_decrease=0.01,\\n    random_state=42,\\n    class_weight=\\\"balanced\\\",\\n    max_samples=0.8,\\n    max_features=0.6,\\n)\\nrf_clf.fit(x_train_resample, y_train_resample)  ## using SMOTE\\n\\n## Pridect and Evaluation\\ny_pred_train_rf = rf_clf.predict(x_train_finall)\\ny_pred_test_rf = rf_clf.predict(x_test_final)\\n\\n\\n# Evaluation\\nf1_rf_train = f1_score(y_train, y_pred_train_rf, average=\\\"micro\\\")\\nf1_rf_test = f1_score(y_test, y_pred_test_rf, average=\\\"micro\\\")\\n\\nprint(f\\\"F1 Score for Training Dataset using RandomForest  {f1_rf_train * 100 :.3f}\\\")\\nprint(f\\\"F1Score for Testing Dataset using RandomForest  {f1_rf_test * 100 :.3f}\\\")\";\n",
       "                var nbb_formatted_code = \"### Bagging------> RandomForestClassifier\\nrf_clf = RandomForestClassifier(\\n    n_estimators=100,\\n    criterion=\\\"gini\\\",\\n    max_depth=10,\\n    max_leaf_nodes=4,\\n    oob_score=True,\\n    min_impurity_decrease=0.01,\\n    random_state=42,\\n    class_weight=\\\"balanced\\\",\\n    max_samples=0.8,\\n    max_features=0.6,\\n)\\nrf_clf.fit(x_train_resample, y_train_resample)  ## using SMOTE\\n\\n## Pridect and Evaluation\\ny_pred_train_rf = rf_clf.predict(x_train_finall)\\ny_pred_test_rf = rf_clf.predict(x_test_final)\\n\\n\\n# Evaluation\\nf1_rf_train = f1_score(y_train, y_pred_train_rf, average=\\\"micro\\\")\\nf1_rf_test = f1_score(y_test, y_pred_test_rf, average=\\\"micro\\\")\\n\\nprint(f\\\"F1 Score for Training Dataset using RandomForest  {f1_rf_train * 100 :.3f}\\\")\\nprint(f\\\"F1Score for Testing Dataset using RandomForest  {f1_rf_test * 100 :.3f}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Bagging------> RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=10,\n",
    "    max_leaf_nodes=4,\n",
    "    oob_score=True,\n",
    "    min_impurity_decrease=0.01,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    max_samples=0.8,\n",
    "    max_features=0.6,\n",
    ")\n",
    "rf_clf.fit(x_train_resample, y_train_resample)  ## using SMOTE\n",
    "\n",
    "## Pridect and Evaluation\n",
    "y_pred_train_rf = rf_clf.predict(x_train_finall)\n",
    "y_pred_test_rf = rf_clf.predict(x_test_final)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "f1_rf_train = f1_score(y_train, y_pred_train_rf, average=\"micro\")\n",
    "f1_rf_test = f1_score(y_test, y_pred_test_rf, average=\"micro\")\n",
    "\n",
    "print(f\"F1 Score for Training Dataset using RandomForest  {f1_rf_train * 100 :.3f}\")\n",
    "print(f\"F1Score for Testing Dataset using RandomForest  {f1_rf_test * 100 :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4cfc6",
   "metadata": {},
   "source": [
    "# `XGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea6b4388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Training Dataset using DecisionTree with SMOTE 99.520\n",
      "F1 Score for Testing Dataset using DecisionTree after SMOTE 98.559\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"#### XGBoost\\nxgboost = XGBClassifier(\\n    objective=\\\"binary:logistic\\\",\\n    n_estimators=100,\\n    max_depth=4,\\n    learning_rate=0.9,\\n    subsample=0.7,\\n    reg_lambda=100,\\n    colsample_bytree=0.8,\\n    random_state=41,\\n)\\n\\nxgboost.fit(x_train_resample, y_train_resample)  ## using SMOTE\\n\\n## Pridect and Evaluation\\ny_pred_train_xgboost = xgboost.predict(x_train_finall)\\ny_pred_test_xgboost = xgboost.predict(x_test_final)\\n\\n\\n# Evaluation\\nf1_xgboost_train = f1_score(y_train, y_pred_train_xgboost, average=\\\"micro\\\")\\nf1_xgboost_test = f1_score(y_test, y_pred_test_xgboost, average=\\\"micro\\\")\\n\\nprint(\\n    f\\\"F1 Score for Training Dataset using DecisionTree with SMOTE {f1_xgboost_train * 100 :.3f}\\\"\\n)\\nprint(\\n    f\\\"F1 Score for Testing Dataset using DecisionTree after SMOTE {f1_xgboost_test * 100 :.3f}\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"#### XGBoost\\nxgboost = XGBClassifier(\\n    objective=\\\"binary:logistic\\\",\\n    n_estimators=100,\\n    max_depth=4,\\n    learning_rate=0.9,\\n    subsample=0.7,\\n    reg_lambda=100,\\n    colsample_bytree=0.8,\\n    random_state=41,\\n)\\n\\nxgboost.fit(x_train_resample, y_train_resample)  ## using SMOTE\\n\\n## Pridect and Evaluation\\ny_pred_train_xgboost = xgboost.predict(x_train_finall)\\ny_pred_test_xgboost = xgboost.predict(x_test_final)\\n\\n\\n# Evaluation\\nf1_xgboost_train = f1_score(y_train, y_pred_train_xgboost, average=\\\"micro\\\")\\nf1_xgboost_test = f1_score(y_test, y_pred_test_xgboost, average=\\\"micro\\\")\\n\\nprint(\\n    f\\\"F1 Score for Training Dataset using DecisionTree with SMOTE {f1_xgboost_train * 100 :.3f}\\\"\\n)\\nprint(\\n    f\\\"F1 Score for Testing Dataset using DecisionTree after SMOTE {f1_xgboost_test * 100 :.3f}\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### XGBoost\n",
    "xgboost = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.9,\n",
    "    subsample=0.7,\n",
    "    reg_lambda=100,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=41,\n",
    ")\n",
    "\n",
    "xgboost.fit(x_train_resample, y_train_resample)  ## using SMOTE\n",
    "\n",
    "## Pridect and Evaluation\n",
    "y_pred_train_xgboost = xgboost.predict(x_train_finall)\n",
    "y_pred_test_xgboost = xgboost.predict(x_test_final)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "f1_xgboost_train = f1_score(y_train, y_pred_train_xgboost, average=\"micro\")\n",
    "f1_xgboost_test = f1_score(y_test, y_pred_test_xgboost, average=\"micro\")\n",
    "\n",
    "print(\n",
    "    f\"F1 Score for Training Dataset using DecisionTree with SMOTE {f1_xgboost_train * 100 :.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"F1 Score for Testing Dataset using DecisionTree after SMOTE {f1_xgboost_test * 100 :.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad34fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"### save moddel\\njoblib.dump(xgboost,'xgboost.pkl')\";\n",
       "                var nbb_formatted_code = \"### save moddel\\njoblib.dump(xgboost, \\\"xgboost.pkl\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### save moddel\n",
    "joblib.dump(xgboost, \"xgboost.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
